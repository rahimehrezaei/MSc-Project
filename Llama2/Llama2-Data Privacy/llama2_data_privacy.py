# -*- coding: utf-8 -*-
"""Llama2-Data-Privacy

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cShWlrv3aaWXucOPjwwLC44i4K_257NU
"""

!pip install --upgrade transformers

!pip install transformers torch accelerate
!huggingface-cli login
!huggingface-cli whoami

from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, StoppingCriteria, StoppingCriteriaList
from accelerate import infer_auto_device_map, init_empty_weights, load_checkpoint_and_dispatch
import torch
import json

model_name = "meta-llama/Llama-2-7b-chat-hf"
HF_Token = "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"

# Load the Llama-2 model and tokenizer with the token
tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=HF_Token)
model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=HF_Token)

# Initialize the pipeline
generator = pipeline("text-generation", model=model, tokenizer=tokenizer)

# Define the prompt for Argument from Definition

scheme = "Argument from similarity"
stance = "pro"
topic = "How should companies approach data privacy to protect their users?"

"""**Similarity**"""

argument_similarity = "Physical security is similar to data privacy because both involve protection. Therefore, what is true for physical security should also be true for data privacy."


prompt = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_similarity}"
    "Answer: \n"
)

# Generate the argument
outputs = generator(prompt, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-similarity-data-privacy.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from Similarity",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-similarity-data-privacy.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Criterion**"""

argument_criterion = "Companies should prioritize data privacy because it is essential for maintaining user trust."


prompt2 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_criterion}"
    "Answer: \n"
)

# Generate the argument
outputs = generator(prompt2, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-criterion-data-privacy.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from criterion",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-criterion-data-privacy.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Authority**"""

argument_authority = "Companies should prioritize data privacy because it is essential for maintaining user trust."



prompt4 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_authority}"
    "Answer: \n"
)

# Generate the argument
outputs = generator(prompt4, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-authority-data-privacy.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from authority",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-authority-data-privacy.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Example**"""

argument_example = "The 2017 Equifax data breach, which exposed the personal information of millions of users, demonstrates the critical need for robust data privacy measures. Therefore, companies should prioritize strong data privacy practices."


prompt5 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_example}"
    "Answer: \n"
)

# Generate the argument
outputs = generator(prompt5, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-example-data-privacy.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from example",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-example-data-privacy.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Goal**"""

# Create the argument from goals
argument_goal = "The goal is to protect users' personal information. Implementing robust data privacy measures is a means to achieve this goal. Therefore, companies should implement robust data privacy measures."


prompt6 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_goal}"
    "Answer: \n"
)

# Generate the argument
outputs = generator(prompt6, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-goal-data-privacy.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from goal",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-goal-data-privacy.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Commitment**"""

#P: Companies
#A: Companies are committed to user trust.
#B: Companies should protect data privacy.
#Scheme: Person P is committed to proposition A. Therefore, P should accept B (if B is a logical consequence of A).

argument_commitment = "Companies are committed to user trust. Protecting data privacy is essential for trust. Therefore, companies should protect data privacy."



prompt7 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_commitment}"
    "Answer: \n"
)

# Generate the argument
outputs = generator(prompt7, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-commitment-data-privacy.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from commitment",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-commitment-data-privacy.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Consequences**"""

argument_consequences = "If companies protect data privacy, user trust will increase. Therefore, companies should protect data privacy."


prompt8 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_consequences}"
    "Answer: \n"
)

# Generate the argument
outputs = generator(prompt8, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-consequences-data-privacy.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from consequences",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-consequences-data-privacy.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Cause of effect**"""

argument_cause_effect = "Neglecting data privacy causes data breaches. Companies are neglecting data privacy. Therefore, data breaches will occur."


prompt9 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_cause_effect}"
    "Answer: \n"
)

# Generate the argument
outputs = generator(prompt9, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-cause_effect-data-privacy.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from cause_effect",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-cause_effect-data-privacy.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Equality**"""

#Form: "a is X, because b is X."

#a: Employees
#b: Customers
#X: Need data privacy

argument_equality = "Employees need data privacy because customers need data privacy."


prompt10 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_equality}"
    "Answer: \n"
)

# Generate the argument
outputs = generator(prompt10, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-equality-data-privacy.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from equality",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-equality-data-privacy.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Popular opinion**"""

# A: Companies should protect data privacy.
#Scheme: Most people believe that A is true. Therefore, A is true.

argument_popular_opinion = "Most people believe that companies should protect data privacy. Therefore, companies should protect data privacy."

prompt11 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_popular_opinion}"
    "Answer: \n"
)

# Generate the argument
outputs = generator(prompt11, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-popular_opinion-data-privacy.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from popular_opinion",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-popular_opinion-data-privacy.json", "w") as file:
    json.dump(data, file, indent=4)