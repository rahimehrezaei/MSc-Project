# -*- coding: utf-8 -*-
"""Llama2-climate-whole

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oohaCxgwQFD4lP4xHbc2DdHlIFxnFkab
"""

!pip install --upgrade transformers

!pip install transformers torch accelerate
!huggingface-cli login
!huggingface-cli whoami

from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, StoppingCriteria, StoppingCriteriaList
from accelerate import infer_auto_device_map, init_empty_weights, load_checkpoint_and_dispatch
import torch
import json

model_name = "meta-llama/Llama-2-7b-chat-hf"
HF_Token = "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"

# Load the Llama-2 model and tokenizer with the token
tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=HF_Token)
model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=HF_Token)

# Initialize the pipeline
generator = pipeline("text-generation", model=model, tokenizer=tokenizer)

# Define the prompt for Argument from Definition

scheme = "Argument from similarity"
stance = "pro"
topic = "Is climate change mainly caused by human activities?"

"""**Similarity**"""

argument_similarity = "Human activities are similar to burning fossil fuels because both cause environmental damage. Therefore, if burning fossil fuels causes climate change, human activities likely do as well."


prompt = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_similarity}"
)

# Generate the argument
outputs = generator(prompt, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-similarity-climate.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from Similarity",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-similarity-climate.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Criterion**"""

argument_criterion = "Human activities are the cause of climate change because they increase greenhouse gases."


prompt2 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_criterion}"
)

# Generate the argument
outputs = generator(prompt2, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-criterion-climate.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from criterion",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-criterion-climate.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Authority**"""

argument_authority = "Climate change is mainly caused by human activities because leading climate scientists agree it is."


prompt4 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_authority}"
)

# Generate the argument
outputs = generator(prompt4, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-authority-climate.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from authority",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-authority-climate.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Example**"""

argument_example = "Wildfires in Australia, worsened by human-caused high temperatures, show that climate change is mainly caused by human activities. Therefore, climate change is mainly caused by human activities."


prompt5 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_example}"

)

# Generate the argument
outputs = generator(prompt5, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-example-climate.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from example",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-example-climate.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Goal**"""

argument_goal = "The goal is to reduce the impact of climate change. Reducing human activities that emit greenhouse gases is a means to achieve this goal. Therefore, we should reduce human activities that emit greenhouse gases."


prompt6 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_goal}"
)

# Generate the argument
outputs = generator(prompt6, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-goal-climate.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from goal",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-goal-climate.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Commitment**"""

argument_commitment = "Governments are committed to protecting citizens. Therefore, they should reduce human activities causing climate change to fulfill this commitment."


prompt7 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_commitment}"
)

# Generate the argument
outputs = generator(prompt7, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-commitment-climate.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from commitment",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-commitment-climate.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Consequences**"""

argument_consequences = "If human activities that cause emissions are reduced, climate change will slow down. Therefore, emissions should be reduced."


prompt8 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_consequences}"
)

# Generate the argument
outputs = generator(prompt8, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-consequences-climate.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from consequences",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-consequences-climate.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Cause of effect**"""

argument_cause_effect = "Burning fossil fuels increases greenhouse gases. Fossil fuel use is ongoing. Therefore, greenhouse gas levels will continue to rise."


prompt9 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_cause_effect}"
    "Answer: \n"
)

# Generate the argument
outputs = generator(prompt9, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-cause_effect-climate.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from cause_effect",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-cause_effect-climate.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Equality**"""

argument_equality = "Human activities should be recognized as causes of climate change, because natural processes are recognized as causes of climate change."


prompt10 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_equality}"
    "Answer: \n"
)
# Generate the argument
outputs = generator(prompt10, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-equality-climate.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from equality",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-equality-climate.json", "w") as file:
    json.dump(data, file, indent=4)

"""**Popular opinion**"""

argument_popular_opinion = "Most people believe that climate change is mainly caused by human activities. Therefore, it is true that human activities are the main cause of climate change."
prompt11 = (
    f"Generate an argument using the {scheme} approach, focusing on a {stance} perspective for the topic {topic}."
    f"Ensure the argument supports a pro stance exclusively, without any opposing viewpoints."
    f"The argument should be structured according to this format: {argument_popular_opinion}"
    "Answer: \n"
)

# Generate the argument
outputs = generator(prompt11, max_length=250, temperature=0.9, num_return_sequences=1, do_sample=True, truncation=True)

# Extract the generated text starting after "Answer:"
generated_text = outputs[0]["generated_text"]
argument_start = generated_text.split("Answer:")[1].strip()  # Get the text after "Answer:"

# Find the last complete sentence by locating the last period (".")
last_period_index = argument_start.rfind(".")
if last_period_index != -1:
    complete_argument = argument_start[:last_period_index + 1].strip()  # Keep text up to and including the last "."
else:
    complete_argument = argument_start  # In case there is no period, use the whole text

# Print the complete argument
print(complete_argument)

# Save the output to a text file
with open("Llama2-popular_opinion-climate.txt", "w") as file:
    file.write(complete_argument)

# Prepare the data to save as JSON
data = {
    "topic": topic,
    "argument_scheme": "Argument from popular_opinion",
    "generated_argument": complete_argument
}

# Save the output to a JSON file
with open("Llama2-popular_opinion-climate.json", "w") as file:
    json.dump(data, file, indent=4)